model:
  input_shape: [1, 11, 24, 5]
  target_shape: [1, 11, 24, 1]
  base_units: 64
  # block_units: null
  scale_alpha: 1.0

  enc_depth: [1, 1]
  enc_cuboid_size: [1, 4, 4]
  enc_cuboid_strategy: ['l', 'l']
  enc_shift_size: [0, 0, 0]

  dec_depth: [1, 1]
  dec_cuboid_size: [1, 4, 4]
  dec_cuboid_strategy: ['l', 'l']
  dec_shift_size: [0, 0, 0]

  enc_use_inter_ffn: true
  dec_use_inter_ffn: true
  dec_hierarchical_pos_embed: false

  downsample: 2
  downsample_type: "patch_merge"
  upsample_type: "upsample"

  num_global_vectors: 0
  use_dec_self_global: false
  dec_self_update_global: true
  use_dec_cross_global: false
  use_global_vector_ffn: false
  use_global_self_attn: false
  separate_global_qkv: false
  global_dim_ratio: 1

  #self_pattern: 1
  #cross_self_pattern: "axial"
  cross_pattern: "cross_1x1"
  dec_cross_last_n_frames: null

  attn_drop: 0.1
  proj_drop: 0.1
  ffn_drop: 0.1
  num_heads: 4

  ffn_activation: "gelu"
  gated_ffn: false
  norm_layer: "layer_norm"
  padding_type: "zeros"
  pos_embed_type: "t+h+w"
  use_relative_pos: true
  self_attn_use_final_proj: true
  dec_use_first_self_attn: false

  z_init_method: "zeros"
  initial_downsample_type: "conv"
  initial_downsample_activation: "leaky"
  initial_downsample_scale: [1, 2, 2]
  initial_downsample_conv_layers: 2
  final_upsample_conv_layers: 1
  checkpoint_level: 0

  attn_linear_init_mode: "0"
  ffn_linear_init_mode: "0"
  conv_init_mode: "0"
  down_up_linear_init_mode: "0"
  norm_init_mode: "0"
